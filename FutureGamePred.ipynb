{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa424b-5bea-459f-9e63-76943401f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import itertools\n",
    "import datetime as dt\n",
    "start = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c63f1-a2fd-498e-8d3e-05ec1ca682b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute this to run in a particular directory that you supply here.\n",
    "os.chdir(\"/Users/dfox/WPI/WPIClasses/DS502StatisticalMethodsForDataScience/FinalProject/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723dc63c-4a3d-4771-89e2-27c723b7d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time(x):\n",
    "    print(f\"{x}: elapsed time {dt.datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9e6c45-511d-417f-aa32-eab1d43d8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_hash(x):\n",
    "    random.seed(23)\n",
    "    return hash(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3934d-3868-42aa-acf2-995ed61e96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_KFOLD = 5\n",
    "START_TRAIN_YEAR = 1993\n",
    "END_TEST_YEAR = 2023\n",
    "CV_SPLIT_SIZE = math.floor((END_TEST_YEAR-START_TRAIN_YEAR) / (CV_KFOLD+2)) # 4\n",
    "START_TEST_YEAR = START_TRAIN_YEAR + (CV_SPLIT_SIZE * (CV_KFOLD+1)) # 2017\n",
    "BETTING_THRESHOLD = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f602e7-453f-429b-ac63-6fa29263f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# uncomment/comment to vary on the parameters you wish to\n",
    "hyperparams = {'lag': {'V': [['NP', 'FirstDowns', 'RushAtt', 'RushYards', \n",
    "                              'RushTD',\n",
    "                              'PassComp', 'PassAtt', 'PassYards', 'PassTD',\n",
    "                              'PassInt', 'Sacked', 'SackedYards', \n",
    "                              'NetPassYards',\n",
    "                              'NetTotalYards', 'Fumbles', 'FumblesLost',\n",
    "                              'Turnovers', 'Penalties', 'PenaltyYards', \n",
    "                              'TimeOfPossesion', 'Q1S', 'Q2S', 'Q3S', 'Q4S',\n",
    "                              'OTS']],\n",
    "                       'N': [16, 28, 30, 41],\n",
    "                       'S': [9, 5, 1]},\n",
    "               # 'avg': {'N': [32, 24, 16, 8],\n",
    "                       # 'W': [0.2, 0.1, 0.3],\n",
    "                       # 'S': [9, 5, 1]}\n",
    "               # 'avg': {'N': [36, 28],\n",
    "               #         'W': [0.2],\n",
    "               #         'S': [5]}\n",
    "               # 'avg': {'N': [48, 40],\n",
    "               #         'W': [0.2],\n",
    "               #         'S': [5]}\n",
    "               # 'avg': {'N': [44, 38],\n",
    "               #         'W': [0.2],\n",
    "               #         'S': [5]}\n",
    "               # 'avg': {'N': [42, 39],\n",
    "               #         'W': [0.2],\n",
    "               #         'S': [5]}\n",
    "               # 'avg': {'N': [41],\n",
    "               #         'W': [0.2],\n",
    "               #         'S': [5]}\n",
    "                'avg': {'N': [28, 32, 36, 41],\n",
    "                        'W': [0.2, 0.3],\n",
    "                        'S': [5]}\n",
    "               # 'avg': {'N': [41],\n",
    "               #         'W': [0.15, 0.25],\n",
    "               #         'S': [5]}\n",
    "               # 'avg': {'N': [41],\n",
    "               #         'W': [0.2],\n",
    "               #         'S': [3, 4, 6, 7, 8]}\n",
    "\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298cc2a-7f21-4e78-b3e0-e2da08935de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_params = { 'linear':     {'model': LinearRegression,\n",
    "                            'params': {},\n",
    "                            'normalize': False\n",
    "                            },\n",
    "              'ridge':      {'model': Ridge,\n",
    "                            'params': {'alpha': [0.1, 1.0, 10.0],\n",
    "                                        'tol': [0.0001, 0.00001],\n",
    "                                        'random_state': [23]\n",
    "                                        },\n",
    "                            'normalize': True\n",
    "                            },\n",
    "              'svr':        {'model': SVR,\n",
    "                            'params': {'kernel': ['linear', 'poly', 'rbf'],\n",
    "                                        'C': [0.1, 1.0],\n",
    "                                        'tol': [0.0001, 0.00001],\n",
    "                                        'degree': [2, 3]\n",
    "                                        },\n",
    "                            'normalize': True\n",
    "                            },\n",
    "              'rforest':    {'model': RandomForestRegressor,\n",
    "                            'params': {'max_depth': [3, 5, 10],\n",
    "                                        'n_estimators': [50, 100, 150],\n",
    "                                        'random_state': [23],\n",
    "                                        'n_jobs': [-1]\n",
    "                                        },\n",
    "                            'normalize': True\n",
    "                            },\n",
    "              'knn':        {'model': KNeighborsRegressor,\n",
    "                            'params': {'n_neighbors': [1, 3, 5, 10, 15],\n",
    "                                        'p': [1, 2]\n",
    "                                        },\n",
    "                            'normalize': True\n",
    "                            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477edd0-b5a1-4545-a740-ece867869b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_list(params_dict):\n",
    "    keys = params_dict.keys()\n",
    "    vals = params_dict.values()\n",
    "    \n",
    "    combinations = list(itertools.product(*vals))\n",
    "    return [dict(zip(keys, combination)) for combination in combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2425f-d265-485f-bfde-47f8a0a1351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record_by_threshold(threshold_min, threshold_max, betspread,\n",
    "                            predspread, gamespread):\n",
    "    class_pred = predspread + betspread\n",
    "    class_pred_list = class_pred.tolist()\n",
    "    for i, pred in enumerate(class_pred_list):\n",
    "        if abs(pred) < threshold_min or abs(pred > threshold_max):\n",
    "            class_pred_list[i] = 0.0\n",
    "    class_Y = gamespread + betspread\n",
    "    class_Y_list = class_Y.tolist()\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    for i in range(len(class_pred_list)):\n",
    "        outcome = class_pred_list[i] * class_Y_list[i]\n",
    "        if round(outcome, 2) > 0.00:\n",
    "            wins += 1\n",
    "        elif round(outcome, 2) < 0.00:\n",
    "            losses += 1\n",
    "    return wins, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af202837-967e-4847-855d-da1d6ca2a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_construct_lag(hyper):\n",
    "    N = hyper['N']\n",
    "    # W = hyper['W']\n",
    "    variables = hyper['V']\n",
    "    print(variables)\n",
    "    # X = hyper['X']\n",
    "    \n",
    "    x = '_'.join([f\"{key}={str(val)}\"\n",
    "                  for key, val in sorted(hyper.items()) if key != 'V'])\n",
    "    for var in variables:\n",
    "        x+= f\"_{var}\"\n",
    "    z = do_hash(x)\n",
    "\n",
    "    if os.path.exists(f\"NFLPred_lag_{z}.csv\"):\n",
    "        data = pd.read_csv(f\"NFLPred_lag_{z}.csv\")\n",
    "        if \"Unnamed: 0\" in data:\n",
    "            data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "        print_time(f\"Recieved X from cache file NFLPred_lag_{z}.csv\")\n",
    "        return data.copy()\n",
    "\n",
    "    print_time(f\"Construct lag X, will place in file NFLPred_lag_{z}.csv\")\n",
    "\n",
    "    games = pd.read_csv('NFLGamesDB19871993Fixed.csv', index_col=False)\n",
    "    if \"Unnamed: 0\" in games:\n",
    "        games.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    games.sort_values(by = ['Year', 'Week', 'Date'], inplace = True,\n",
    "                      ascending=True)\n",
    "    # games.head()\n",
    "\n",
    "    print_time(\"Loaded NFL Games\")\n",
    "\n",
    "    games['VNP'] = games.VScore - games.HScore\n",
    "    games['HNP'] = games.HScore - games.VScore\n",
    "    games['RegSeason'] = games.YearWeekDesc.str.contains('Week', na=True).astype(int)\n",
    "    games['Playoffs'] = (games.RegSeason == 0).astype(int)\n",
    "    games.drop('RegSeason', axis=1, inplace=True)\n",
    "    games['Spread'] = games['VNP']\n",
    "    games['BetSpread'] = games['VSpread']    \n",
    "    \n",
    "    names = pd.read_csv('TeamNamesMap.csv')\n",
    "\n",
    "    print_time(\"Loaded NFL Teams Map, constructing symbol replacements\")\n",
    "\n",
    "    codes = pd.DataFrame(columns = ['Team_Name', 'Year', 'Team_Symbol'])\n",
    "    for i in range(len(names)):\n",
    "        name = names.iloc[i, 0]\n",
    "        begin = names.iloc[i, 1]\n",
    "        end = names.iloc[i, 2]\n",
    "        symbol = names.iloc[i, 3]\n",
    "        for y in range(begin, end + 1):\n",
    "            patch = pd.DataFrame({'Team_Name': [name], 'Year': [y], \n",
    "                                  'Team_Symbol': [symbol]})\n",
    "            codes = pd.concat([codes, patch], ignore_index = True, axis = 0)\n",
    "        \n",
    "    visitor = codes.copy().rename(columns = {'Team_Name': 'Visitor'})\n",
    "    home = codes.copy().rename(columns = {'Team_Name': 'Home'})        \n",
    "        \n",
    "    games = pd.merge(games, visitor, on = ['Visitor', 'Year'])\n",
    "    games = pd.merge(games, home, on = ['Home', 'Year'])\n",
    "    games.sort_values(by = ['Year', 'Week', 'Date'], inplace = True)\n",
    "        \n",
    "    games.Visitor = games.Team_Symbol_x\n",
    "    games.Home = games.Team_Symbol_y\n",
    "    games.drop(['Team_Symbol_x', 'Team_Symbol_y'], axis = 1, inplace = True)\n",
    "        \n",
    "    game_data = pd.concat([games[['Year', 'Week', 'Date', 'Playoffs', \n",
    "                                  'Visitor', 'Home', 'IsNeutral', 'BetSpread', \n",
    "                                  'Spread']].copy(), \n",
    "                           games.copy().iloc[:, -61:-3]], axis = 1)\n",
    "    game_data.drop(['HThirdDownConv', 'HThirdDownAtt', 'HFourthDownConv', \n",
    "                    'HFourthDownAtt', 'VThirdDownConv', 'VThirdDownAtt', \n",
    "                    'VFourthDownConv', 'VFourthDownAtt'], axis=1, inplace=True)\n",
    "    game_data.dropna(inplace = True)\n",
    "    print_time(f\"cols={game_data.columns}\")\n",
    "\n",
    "    all_variables = ['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home', \n",
    "                     'IsNeutral', 'BetSpread', 'Spread'] + variables\n",
    "    print_time(f\"all variables{all_variables}\")\n",
    "    \n",
    "    teams = list(game_data.Visitor.value_counts().index)\n",
    "    game_list = ['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home', \n",
    "                 'IsNeutral', 'BetSpread', 'Spread']\n",
    "    home_list = game_list + [col for col in game_data.columns\n",
    "                             if col[0] == 'H' and col != 'Home']\n",
    "    visit_list = game_list + [col for col in game_data.columns\n",
    "                              if col[0] == 'V' and col != 'Visitor']\n",
    "    team_stat = {}\n",
    "    for team in teams:\n",
    "        print_time(f\"Constructing variables for team {team}\")\n",
    "        team_stat[team] = pd.DataFrame(columns = all_variables)\n",
    "        temp = game_data[(game_data.Home == team)][home_list]\n",
    "        temp.columns = all_variables\n",
    "        team_stat[team] = pd.concat([team_stat[team], temp])\n",
    "        temp = game_data[(game_data.Visitor == team)][visit_list]\n",
    "        temp.columns = all_variables\n",
    "        team_stat[team] = pd.concat([team_stat[team], temp])\n",
    "        team_stat[team].sort_values(by = ['Year', 'Week', 'Date'], \n",
    "                                    inplace = True)\n",
    "    \n",
    "    lag_variables = []\n",
    "    for i in range(1, N + 1):\n",
    "        lag_variables += ['lag' + str(i) + col for col in game_data.columns \n",
    "                          if ((col[0] == 'H' and col != 'Home') or \n",
    "                              (col[0] == 'V' and col != 'Visitor' \n",
    "                               and col != 'VSpread'))]    \n",
    "    \n",
    "    past_game_stat = pd.DataFrame(columns = ['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home', 'IsNeutral', 'BetSpread', 'Spread'] + lag_variables)\n",
    "    past_game_stat[['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home',\n",
    "                    'IsNeutral', 'BetSpread', 'Spread']] =\\\n",
    "        game_data[['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home',\n",
    "                   'IsNeutral', 'BetSpread', 'Spread']]\n",
    "    \n",
    "    past_game_stat = pd.DataFrame(columns = ['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home', 'IsNeutral', 'BetSpread', 'Spread'] + lag_variables)\n",
    "    past_game_stat[['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home', \n",
    "                    'IsNeutral', 'BetSpread', 'Spread']] =\\\n",
    "        game_data[['Year', 'Week', 'Date', 'Playoffs', 'Visitor', 'Home', \n",
    "                   'IsNeutral', 'BetSpread', 'Spread']]\n",
    "    past_game_stat.sort_values(by = ['Year', 'Week', 'Date'], inplace = True)\n",
    "    for team in teams:\n",
    "        print_time(f\"Constructing lag variables for team {team}\")\n",
    "        home_dates = past_game_stat.loc[past_game_stat['Home'] == team, 'Date']\n",
    "        visit_dates = past_game_stat.loc[past_game_stat['Visitor'] == team, \n",
    "                                         'Date']\n",
    "        temp = team_stat[team].copy()\n",
    "        for i in range(1, N + 1):\n",
    "            lag_values = temp.iloc[:, 9:].shift(i)\n",
    "            home_vars = [col for col in lag_variables \n",
    "                         if col.startswith('lag' + str(i) + 'H')]\n",
    "            visit_vars = [col for col in lag_variables \n",
    "                          if col.startswith('lag' + str(i) + 'V')]\n",
    "            past_game_stat.loc[game_data.Home == team, home_vars] =\\\n",
    "                lag_values[temp.Date.isin(home_dates)].values\n",
    "            past_game_stat.loc[game_data.Visitor == team, visit_vars] =\\\n",
    "                lag_values[temp.Date.isin(visit_dates)].values    \n",
    "\n",
    "    past_game_stat.sort_values(by = ['Year', 'Week', 'Date'], inplace = True)\n",
    "    past_game_stat.dropna(inplace = True)\n",
    "    \n",
    "    \n",
    "    data = past_game_stat.copy().merge(games[['Year', 'Week', 'Date', \n",
    "                                              'Playoffs', 'Visitor', 'Home', \n",
    "                                              'IsNeutral', 'BetSpread', \n",
    "                                              'Spread']],\n",
    "                                       on = ['Year', 'Week', 'Date', \n",
    "                                             'Playoffs', 'Visitor', 'Home', \n",
    "                                             'IsNeutral', 'BetSpread', \n",
    "                                             'Spread'])\n",
    "\n",
    "    data.to_csv(f\"NFLPred_lag_{z}.csv\")\n",
    "    \n",
    "    return data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9810a-87d9-4fef-9ba6-52e0746abd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_construct_avg(hyper):\n",
    "    N = hyper['N']\n",
    "    W = hyper['W']\n",
    "    if 'V' in hyper and (len(hyper['V']) > 1 or hyper['V'][0] != 'NP'):\n",
    "        return None\n",
    "    variables = ['NP']\n",
    "    \n",
    "    x = '_'.join([f\"{key}={str(val)}\"\n",
    "                  for key, val in sorted(hyper.items()) if key != 'V'])\n",
    "    for var in variables:\n",
    "        x += f\"_{var}\"\n",
    "    z = do_hash(x)\n",
    "\n",
    "    if os.path.exists(f\"NFLPred_avg_{z}.csv\"):\n",
    "        gdl_df = pd.read_csv(f\"NFLPred_avg_{z}.csv\")\n",
    "        if \"Unnamed: 0\" in gdl_df:\n",
    "            gdl_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "        print_time(f\"Recieved X from cache file NFLPred_avg_{z}.csv\")\n",
    "        return gdl_df.copy()\n",
    "\n",
    "    print_time(f\"Construct avg X, will place in file NFLPred_avg_{z}.csv\")\n",
    "\n",
    "    games = pd.read_csv('NFLGamesDB19871993Fixed.csv', index_col=False)\n",
    "    if \"Unnamed: 0\" in games:\n",
    "        games.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    games.sort_values(by = ['Year', 'Week', 'Date'], inplace = True, \n",
    "                      ascending=True)\n",
    "\n",
    "    names = pd.read_csv('TeamNamesMap.csv')\n",
    "\n",
    "    codes = pd.DataFrame(columns = ['Team_Name', 'Year', 'Team_Symbol'])\n",
    "    for i in range(len(names)):\n",
    "        name = names.iloc[i, 0]\n",
    "        begin = names.iloc[i, 1]\n",
    "        end = names.iloc[i, 2]\n",
    "        symbol = names.iloc[i, 3]\n",
    "        for y in range(begin, end + 1):\n",
    "            patch = pd.DataFrame({'Team_Name': [name], 'Year': [y], 'Team_Symbol': [symbol]})\n",
    "            codes = pd.concat([codes, patch], ignore_index = True, axis = 0)\n",
    "        \n",
    "    visitor = codes.copy().rename(columns = {'Team_Name': 'Visitor'})\n",
    "    home = codes.copy().rename(columns = {'Team_Name': 'Home'})        \n",
    "        \n",
    "    games = pd.merge(games, visitor, on = ['Visitor', 'Year'])\n",
    "    games = pd.merge(games, home, on = ['Home', 'Year'])\n",
    "    games.sort_values(by = ['Year', 'Week', 'Date'], inplace = True)\n",
    "        \n",
    "    games.Visitor = games.Team_Symbol_x\n",
    "    games.Home = games.Team_Symbol_y\n",
    "    games.drop(['Team_Symbol_x', 'Team_Symbol_y'], axis = 1, inplace = True)\n",
    "        \n",
    "    games['Spread'] = games['VScore'] - games['HScore']\n",
    "    games['RegSeason'] = games.YearWeekDesc.str.contains('Week', na=True).\\\n",
    "        astype(int)\n",
    "    games['Playoffs'] = (games.RegSeason == 0).astype(int)\n",
    "    games['BetSpread'] = games['VSpread']\n",
    "    games.drop(['RegSeason', 'VSpread'], axis=1, inplace=True)\n",
    "        \n",
    "    teams = list(games.Visitor.value_counts().index)\n",
    "    calculated_variables = ['VNRPA', 'VNYA'] + teams\n",
    "    inherited_variables = ['Year', 'Week', 'Date', 'Visitor', 'Home', \n",
    "                           'IsNeutral', 'Spread', 'BetSpread', 'Playoffs']\n",
    "\n",
    "    gdl_df = games[games.Year >= 1973].copy()\n",
    "    gdl_df = gdl_df[inherited_variables].copy()\n",
    "    for var in calculated_variables:\n",
    "        gdl_df[var] = 0.0\n",
    "\n",
    "    i = 0\n",
    "    for index, row in gdl_df.iterrows():\n",
    "        if i % 100 == 0:\n",
    "            print_time(f\"processing row {i} for gdl_df\")\n",
    "        i += 1\n",
    "        v_team = row.Visitor\n",
    "        v_games = games[((games.Visitor == v_team) | (games.Home == v_team))]\n",
    "        v_games = v_games[((v_games.Year < row.Year)\n",
    "                           | ((v_games.Year == row.Year) \n",
    "                              & (v_games.Week < row.Week)))]\n",
    "        v_games = v_games[-N:]\n",
    "        h_team = row.Home\n",
    "        h_games = games[((games.Visitor == h_team) \n",
    "                         | (games.Home == h_team))]\n",
    "        h_games = h_games[((h_games.Year < row.Year) \n",
    "                           | ((h_games.Year == row.Year) \n",
    "                              & (h_games.Week < row.Week)))]\n",
    "        h_games = h_games[-N:]\n",
    "        visitor_net_reg_points_total = 0.0\n",
    "        visitor_net_yards_total = 0.0\n",
    "        divisor = 0.0\n",
    "        teams_dict = {team: 0.0 for team in teams}\n",
    "        for v_index, v_row in v_games.iterrows():\n",
    "            weight = W**(row.Year - v_row.Year)\n",
    "            assert(weight > 0.0)\n",
    "            visitor_net_reg_points = weight*((v_row['VScore'] - v_row['VOTS'])\n",
    "                                             - (v_row['HScore'] \n",
    "                                                - v_row['HOTS']))\n",
    "            visitor_net_yards = weight*(v_row['VNetTotalYards']\n",
    "                                        - v_row['HNetTotalYards'])\n",
    "            divisor += weight\n",
    "            if v_row.Visitor == v_team:\n",
    "                visitor_net_reg_points_total += visitor_net_reg_points\n",
    "                visitor_net_yards_total += visitor_net_yards\n",
    "                teams_dict[v_row.Home] += weight\n",
    "            else:\n",
    "                visitor_net_reg_points_total -= visitor_net_reg_points\n",
    "                visitor_net_yards_total -= visitor_net_yards\n",
    "                teams_dict[v_row.Visitor] += weight\n",
    "        if divisor == 0.0:\n",
    "            # no previous games played, expansion team, just set averages to 0\n",
    "            visitor_net_reg_points_avg = 0.0\n",
    "            visitor_net_yards_avg = 0.0\n",
    "        else:\n",
    "            visitor_net_reg_points_avg = visitor_net_reg_points_total / divisor\n",
    "            visitor_net_yards_avg = visitor_net_yards_total / divisor\n",
    "        visitor_net_reg_points_total = 0.0\n",
    "        visitor_net_yards_total = 0.0\n",
    "        divisor = 0.0\n",
    "        for h_index, h_row in h_games.iterrows():\n",
    "            weight = W**(row.Year - h_row.Year)\n",
    "            assert(weight > 0.0)\n",
    "            visitor_net_reg_points = weight*((h_row['VScore'] - h_row['VOTS']) \n",
    "                                             - (h_row['HScore'] \n",
    "                                                - h_row['HOTS']))\n",
    "            visitor_net_yards = weight*(h_row['VNetTotalYards'] \n",
    "                                        - h_row['HNetTotalYards'])\n",
    "            divisor += weight\n",
    "            if h_row.Visitor == h_team:\n",
    "                visitor_net_reg_points_total += visitor_net_reg_points\n",
    "                visitor_net_yards_total += visitor_net_yards\n",
    "                teams_dict[h_row.Home] -= weight\n",
    "            else:\n",
    "                visitor_net_reg_points_total -= visitor_net_reg_points\n",
    "                visitor_net_yards_total -= visitor_net_yards\n",
    "                teams_dict[h_row.Visitor] -= weight\n",
    "        if divisor == 0.0:\n",
    "            # no previous games played, expansion team, just set averages to 0\n",
    "            home_net_reg_points_avg = 0.0\n",
    "            home_net_yards_avg = 0.0\n",
    "        else:\n",
    "            home_net_reg_points_avg = visitor_net_reg_points_total / divisor\n",
    "            home_net_yards_avg = visitor_net_yards_total / divisor\n",
    "        gdl_df.at[index, 'VNRPA'] = (visitor_net_reg_points_avg \n",
    "                                     - home_net_reg_points_avg)\n",
    "        gdl_df.at[index, 'VNYA'] = (visitor_net_yards_avg - home_net_yards_avg)\n",
    "        for team in teams_dict:\n",
    "            gdl_df.at[index, team] = teams_dict[team]\n",
    "            \n",
    "    gdl_df.drop('VNYA', axis=1, inplace=True)\n",
    "    \n",
    "    gdl_df.to_csv(f\"NFLPred_avg_{z}.csv\")\n",
    "    \n",
    "    return gdl_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a1688-0da6-4b21-9464-3112a4f0ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_X(df, cols):\n",
    "    cdf = df.copy()\n",
    "    for col in cols:\n",
    "        if df[col].max() == cdf[col].min():\n",
    "            if cdf[col].max() < 0.5:\n",
    "                cdf[col] = 0\n",
    "            else:\n",
    "                cdf[col] = 1\n",
    "        else:\n",
    "            cdf[col] = (cdf[col] - cdf[col].min())/(cdf[col].max() \n",
    "                                                    - cdf[col].min())\n",
    "    return cdf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e249fd-96a7-4997-ad88-fa4787c77b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_cv_results_input(cv_results_input):\n",
    "    xstr = json.dumps(cv_results_input)\n",
    "    return str(do_hash(xstr))\n",
    "\n",
    "def cv_results_insert(all_dict, cv_results):\n",
    "    cv_results_input_hash = hash_cv_results_input(cv_results['input'])\n",
    "    if cv_results_input_hash in all_dict:\n",
    "        for i, r in enumerate(all_dict[cv_results_input_hash]):\n",
    "            if r['input'] == cv_results['input']:\n",
    "                all_dict[cv_results_input_hash][i] = cv_results\n",
    "                return\n",
    "        all_dict[cv_results_input_hash].append(cv_results)\n",
    "        return\n",
    "    all_dict[cv_results_input_hash] = [cv_results]\n",
    "    with open(\"cv_results_nfl.json\", \"w\") as fp:\n",
    "        json.dump(all_dict, fp, indent=4)\n",
    "    \n",
    "def cv_results_get(all_dict, cv_results_input):\n",
    "    cv_results_input_hash = hash_cv_results_input(cv_results_input)\n",
    "    if cv_results_input_hash in all_dict:\n",
    "        for r in all_dict[cv_results_input_hash]:\n",
    "            if r['input'] == cv_results_input:\n",
    "                return r\n",
    "    return None\n",
    "\n",
    "# cv_results_get_best(all_dict, mae, False, ['rforest'], ['lag']\n",
    "                    \n",
    "def cv_results_get_best(all_dict, tag, maximize, method_filter=None,type_filter=None):\n",
    "    all_list = []\n",
    "    \n",
    "    for cv_results in all_dict:\n",
    "        for result in all_dict[cv_results]:\n",
    "            if (method_filter is not None\n",
    "                and result['input']['method'] in method_filter):\n",
    "                           \n",
    "                if (type_filter is not None\n",
    "                    and result['input']['Xtype'] in type_filter):\n",
    "                    all_list.append(result)\n",
    "                elif type_filter is None:\n",
    "                    all_list.append(result)\n",
    "            elif method_filter is None:\n",
    "                all_list.append(result)\n",
    "    if len(all_list) == 0:\n",
    "        return None\n",
    "    all_list_sorted = sorted(all_list, key=lambda x: x['cv_output'][tag],\n",
    "                             reverse=maximize)\n",
    "    return all_list_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecbf47-1ae6-4798-8acc-49e8db7751b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "# Only run if you wish to tune parameters for the five models in m_params above\n",
    "# Also tunes hyper params in hyperparams above\n",
    "\n",
    "# Saves all cross-validation tuning runs to cv_results_nfl.json in the local directory\n",
    "# Loads that file to begin with so that duplicate runs are not executed\n",
    "# Saves every single cross-validation run for a given parameter combination\n",
    "\n",
    "# If you wish to generate new runs of cross-validation tuning runs, make sure you have\n",
    "# deleted/renamed the cv_results_nfl.json file\n",
    "\n",
    "# Must execute all above before running this\n",
    "\n",
    "if os.path.exists(\"cv_results_nfl.json\"):\n",
    "    with open(\"cv_results_nfl.json\", \"r\") as fp:\n",
    "        all_cv_results = json.load(fp)\n",
    "else:\n",
    "    all_cv_results = {}\n",
    "\n",
    "# Cross-validation to find best parameters\n",
    "hyperparams_lag = get_params_list(hyperparams['lag'])\n",
    "hyperparams_avg = get_params_list(hyperparams['avg'])\n",
    "\n",
    "threshold_list = []\n",
    "\n",
    "for LAG in [True, False]:\n",
    "    if LAG:\n",
    "        hyperparams = hyperparams_lag\n",
    "    else:\n",
    "        hyperparams = hyperparams_avg\n",
    "\n",
    "    for hyper in hyperparams:\n",
    "        if LAG:\n",
    "            X = X_construct_lag(hyper)\n",
    "        else:\n",
    "            X = X_construct_avg(hyper)\n",
    "        if X is None:\n",
    "            continue\n",
    "        \n",
    "        for method in m_params:\n",
    "            print_time(f\"{method}\")\n",
    "            hash_method = do_hash(method)\n",
    "            if m_params[method]['normalize']:\n",
    "                data = normalize_X(X, [col for col in X][9:])\n",
    "            else:\n",
    "                data = X.copy()\n",
    "            params_list = get_params_list(m_params[method]['params'])\n",
    "            if len(params_list) > 0:\n",
    "                params_list.append({})\n",
    "            random.shuffle(params_list)\n",
    "            \n",
    "            for params in params_list:\n",
    "                \n",
    "                cv_results_input = {}\n",
    "                if LAG:\n",
    "                    cv_results_input['Xtype'] = 'lag'\n",
    "                else:\n",
    "                    cv_results_input['Xtype'] = 'avg'\n",
    "                cv_results_input['hyper'] = hyper\n",
    "                cv_results_input['method'] = method\n",
    "                cv_results_input['params'] = params\n",
    "                cv_results_input['start_train_year'] = START_TRAIN_YEAR\n",
    "                cv_results_input['start_test_year'] = START_TEST_YEAR\n",
    "                cv_results_input['kfold'] = CV_KFOLD\n",
    "                cv_results_input['split_size'] = CV_SPLIT_SIZE\n",
    "                cv_results = cv_results_get(all_cv_results, cv_results_input)\n",
    "                if cv_results is not None:\n",
    "                    print(\"already calculated...\")\n",
    "                    continue #already calculated\n",
    "                \n",
    "                rmse_accum = 0.0\n",
    "                mae_accum = 0.0\n",
    "                dollars_accum = 0\n",
    "                accuracy_accum = 0.00\n",
    "                # threshold_accum = 0\n",
    "                r2_accum = 0.0\n",
    "                max_dollars = None\n",
    "                best_threshold = None\n",
    "                for i in range(CV_KFOLD):\n",
    "                    year = START_TRAIN_YEAR + i*CV_SPLIT_SIZE\n",
    "                    train_data = X[((X.Year >= START_TRAIN_YEAR) \n",
    "                                    & (X.Year < year+CV_SPLIT_SIZE)\n",
    "                                    & (X.Week >= hyper['S']))].copy()\n",
    "                    valid_data = X[((X.Year >= year+CV_SPLIT_SIZE) \n",
    "                                    & (X.Year < year+(2*CV_SPLIT_SIZE))\n",
    "                                    & (X.Week >= hyper['S']))]\n",
    "                \n",
    "                    variables = [col for col in X.columns \n",
    "                                 if col not in ['Year', 'Week', 'Date', \n",
    "                                                'Visitor', 'Home', 'Spread', \n",
    "                                                'BetSpread']]\n",
    "                    train_X = train_data[variables].copy()\n",
    "                    valid_X = valid_data[variables].copy()\n",
    "                    train_Y = train_data['Spread']\n",
    "                    valid_Y = valid_data['Spread']\n",
    "                    valid_spread_Y = valid_data['BetSpread']\n",
    "                    valid_class_Y = 0\n",
    "                    if len(params) > 0:\n",
    "                        model = m_params[method]['model'](**params)\\\n",
    "                            .fit(train_X, train_Y)\n",
    "                    else:\n",
    "                        model = m_params[method]['model']()\\\n",
    "                            .fit(train_X, train_Y)\n",
    "                    valid_pred_Y = model.predict(valid_X)\n",
    "                    rmse = mean_squared_error(valid_Y, valid_pred_Y, \n",
    "                                              squared=False)\n",
    "                    rmse_accum += rmse\n",
    "                    mae = mean_absolute_error(valid_Y, valid_pred_Y) \n",
    "                    mae_accum += mae\n",
    "                    r2 = model.score(valid_X, valid_Y)\n",
    "                    wins, losses = get_record_by_threshold(BETTING_THRESHOLD,\n",
    "                                                           50,\n",
    "                                                           valid_spread_Y, \n",
    "                                                           valid_pred_Y,\n",
    "                                                           valid_Y)\n",
    "                    accuracy = wins / (wins + losses)\n",
    "                    accuracy_accum += accuracy\n",
    "                    r2_accum += r2\n",
    "                rmse = rmse_accum / CV_KFOLD\n",
    "                mae = mae_accum / CV_KFOLD\n",
    "                accuracy = accuracy_accum / CV_KFOLD\n",
    "                r2 = r2_accum / CV_KFOLD\n",
    "                \n",
    "                print_time(f\"{method} {hyper} {params} {rmse} {mae} {accuracy}\")\n",
    "                cv_results = {}\n",
    "                cv_results['input'] = cv_results_input\n",
    "                cv_results['cv_output'] = {}\n",
    "                cv_results['cv_output']['rmse'] = rmse\n",
    "                cv_results['cv_output']['mae'] = mae\n",
    "                cv_results['cv_output']['r2'] = r2\n",
    "                cv_results['cv_output']['accuracy'] = accuracy\n",
    "                cv_results_insert(all_cv_results, cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb25419-d573-450c-8797-171fc1c8cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_by_ps(ps):\n",
    "    return 1 / ((10**(-ps/16)) + 1)\n",
    "\n",
    "def win_by_ps(ps):\n",
    "    return ps > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192169c1-a5f9-4e69-9448-48472f7397e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vegas_brier(df):\n",
    "    return brier_score_loss((df['Spread'] > 0), prob_by_ps(-df['BetSpread']))\n",
    "\n",
    "def calc_vegas_rmse(df):\n",
    "    return mean_squared_error(df['Spread'], -df['BetSpread'], squared=False)\n",
    "\n",
    "def calc_our_brier(df, variables, model):\n",
    "    test_prob_pred_Y = prob_by_ps(model.predict(df[variables]))\n",
    "    return brier_score_loss((df['Spread'] > 0), test_prob_pred_Y)\n",
    "    \n",
    "def calc_our_r2(df, variables, model):\n",
    "    return model.score(df[variables], df['Spread'])\n",
    "    \n",
    "def calc_our_rmse(df, test_pred_Y):\n",
    "    return mean_squared_error(df['Spread'], test_pred_Y, squared=False)\n",
    "    \n",
    "def calc_elo_brier():\n",
    "    df = pd.read_csv(\"nfl_elo2.csv\")\n",
    "    df = df[df.season >= 2017].copy()\n",
    "    df['Spread'] = df.score2 - df.score1\n",
    "    df_no_ties = df[df['Spread'] != 0]\n",
    "    return brier_score_loss((df_no_ties['Spread'] > 0), df_no_ties.elo_prob2)\n",
    "    \n",
    "def calc_elo_rmse():\n",
    "    df = pd.read_csv(\"nfl_elo2.csv\")\n",
    "    df = df[df.season >= 2017].copy()\n",
    "    df['Spread'] = df.score2 - df.score1\n",
    "    df_no_ties = df[df.Spread != 0]\n",
    "    return mean_squared_error(df_no_ties.Spread, df_no_ties.spread1_pre, \n",
    "                              squared=False)\n",
    "    \n",
    "def calc_vegas_mae(df):\n",
    "    return mean_absolute_error(df['Spread'], -df['BetSpread'])\n",
    "     \n",
    "def calc_our_mae(df, test_pred_Y):\n",
    "    return mean_absolute_error(df['Spread'], test_pred_Y)\n",
    "    \n",
    "def calc_elo_mae():\n",
    "    df = pd.read_csv(\"nfl_elo2.csv\")\n",
    "    df = df[df.season >= 2017].copy()\n",
    "    df['Spread'] = df.score2 - df.score1\n",
    "    df_no_ties = df[df.Spread != 0]\n",
    "    return mean_absolute_error(df_no_ties.Spread, df_no_ties.spread1_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a63096-ca49-4956-8d26-541e8252a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results generation\n",
    "# Generates results against the test data set\n",
    "# Reads cv_results_nfl.json and sorts based on the desired metric\n",
    "# Selects top cross-validation parameters for each method\n",
    "\n",
    "# Places the results in test_results_nfl.json, which is a dictionary of metrics as keys\n",
    "# and a list of results, one for each method\n",
    "\n",
    "# Must execute everything above\n",
    "# However, for the cross-validation cell, you do not need to run that if\n",
    "# you have already done so\n",
    "\n",
    "# If you do execute the cross-validation cell, but there is a \n",
    "# cv_results_nfl.json, it should be harmless because if \n",
    "# a hyper parameter / method parameter / method combination has been\n",
    "# run before (appears in cv_results_nfl.json), it will simply skip over that\n",
    "# combination and not fit the model again\n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "print_time(\"start\")\n",
    "if os.path.exists(\"cv_results_nfl.json\"):\n",
    "    with open(\"cv_results_nfl.json\", \"r\") as fp:\n",
    "        all_cv_results = json.load(fp)\n",
    "else:\n",
    "    exit(-1)\n",
    "\n",
    "metrics = ['mae']\n",
    "Xtypes = ['avg', 'lag']\n",
    "all_test_results = {}\n",
    "\n",
    "save_fit = None\n",
    "save_test_Y = None\n",
    "save_test_X = None\n",
    "save_test_pred_Y = None\n",
    "\n",
    "for metric in metrics:\n",
    "    print_time(f\"metric {metric}\")\n",
    "    for Xtype in Xtypes:\n",
    "        print_time(f\"X type {Xtype}\")\n",
    "        for method in m_params:\n",
    "            print_time(f\"method {method} in params {m_params[method]['params']}\")\n",
    "            if metric not in all_test_results:\n",
    "                all_test_results[metric] = {}\n",
    "            if Xtype not in all_test_results[metric]:\n",
    "                all_test_results[metric][Xtype] = []\n",
    "            results = cv_results_get_best(all_cv_results, metric, \n",
    "                                          metric=='accuracy',\n",
    "                                          [method], [Xtype])\n",
    "            if results is None:\n",
    "                continue\n",
    "            print_time(f\"Optimizing {metric}, results {results}\")\n",
    "            hyper = results['input']['hyper']\n",
    "            \n",
    "            if results['input']['Xtype'] == 'lag':\n",
    "                X = X_construct_lag(hyper)\n",
    "            else:\n",
    "                X = X_construct_avg(hyper)\n",
    "                \n",
    "            print(f\"X constructed {X}\")\n",
    "            \n",
    "            if m_params[results['input']['method']]['normalize']:\n",
    "                data = normalize_X(X, [col for col in X][9:])\n",
    "            else:\n",
    "                data = X.copy()\n",
    "            \n",
    "            \n",
    "            variables = [col for col in data.columns \n",
    "                         if col not in ['Year', 'Week', 'Date', 'Visitor', \n",
    "                                        'Home', 'Spread', 'BetSpread']]\n",
    "            train_data = data\\\n",
    "                [((data.Year >= results['input']['start_train_year']) \n",
    "                  & (data.Year < results['input']['start_test_year'])\n",
    "                  & (data.Week >= hyper['S']))]\n",
    "            test_data = data\\\n",
    "                [((data.Year >= results['input']['start_test_year']) \n",
    "                  & (data.Year <= END_TEST_YEAR) \n",
    "                  & (data.Week >= hyper['S']))]\n",
    "            print_time(test_data[variables])\n",
    "            train_Y = train_data['Spread']\n",
    "            test_Y = test_data['Spread']\n",
    "            test_betspread_Y = test_data['BetSpread']\n",
    "              \n",
    "            model = m_params[results['input']['method']]['model']\n",
    "            params = results['input']['params']\n",
    "            \n",
    "            print_time(f\"about to fit model {model}\")\n",
    "            \n",
    "            if len(params) > 0:\n",
    "                fit = model(**params).fit(train_data[variables],\n",
    "                                          train_data['Spread'])\n",
    "            else:\n",
    "                fit = model().fit(train_data[variables], train_data['Spread'])\n",
    "            print_time(\"model was fit\")    \n",
    "            test_pred_Y = fit.predict(test_data[variables])\n",
    "            if method == 'linear' and Xtype == 'avg':\n",
    "                save_fit = fit\n",
    "                save_test_Y = test_Y\n",
    "                save_test_X = test_data[variables]\n",
    "                save_test_pred_Y = test_pred_Y\n",
    "            \n",
    "            test_prob_pred_Y = prob_by_ps(test_pred_Y)\n",
    "            wins, losses = get_record_by_threshold(6.0, 50.0, \n",
    "                                                   #BETTING_THRESHOLD,\n",
    "                                                   # 50,\n",
    "                                                   # 5.0,\n",
    "                                                   #calc_our_mae(test_data, \n",
    "                                                   #             test_pred_Y),\n",
    "                                                   test_betspread_Y, \n",
    "                                                   test_pred_Y,\n",
    "                                                   test_data.Spread)\n",
    "            \n",
    "        \n",
    "            dollars = wins * 100 - losses * 115\n",
    "            accuracy = wins / (wins + losses)\n",
    "            \n",
    "            results['test_output'] = {}\n",
    "            to = results['test_output']\n",
    "            # to['threshold'] = threshold\n",
    "            to['accuracy'] = accuracy\n",
    "            to['wins'] = wins\n",
    "            to['losses'] = losses\n",
    "            to['dollars'] = dollars\n",
    "            print_time(\"\")\n",
    "            print(\"\")\n",
    "            print(results)\n",
    "            print(\"With test:\")\n",
    "            print(f\"Best lowest week {hyper['S']}\")\n",
    "            # print(f\"best threshold {threshold}\")\n",
    "            print(f\"best method {results['input']['method']}\")\n",
    "            print(f\"best params {results['input']['params']}\")\n",
    "            print(f\"best accuracy {accuracy}\")\n",
    "            print(f\"best wins {wins}\")\n",
    "            print(f\"best losses {losses}\")\n",
    "            print(f\"best dollars {dollars}\")\n",
    "            \n",
    "            to['our_rmse'] = calc_our_rmse(test_data, test_pred_Y)\n",
    "            to['vegas_rmse'] = calc_vegas_rmse(test_data)\n",
    "            to['elo_rmse'] = calc_elo_rmse()\n",
    "            \n",
    "            print(f\"Our root mean squared error is {to['our_rmse']}\")\n",
    "            print(f\"Vegas root mean squared error is {to['vegas_rmse']}\")\n",
    "            print(f\"ELO root mean squared error is {to['elo_rmse']}\")\n",
    "            \n",
    "            to['our_mae'] = calc_our_mae(test_data, test_pred_Y)\n",
    "            to['vegas_mae'] = calc_vegas_mae(test_data)\n",
    "            to['elo_mae'] = calc_elo_mae()\n",
    "            \n",
    "            print(f\"Our mean absolute error is {to['our_mae']}\")\n",
    "            print(f\"Vegas mean absolute error is {to['vegas_mae']}\")\n",
    "            print(f\"ELO mean absolute error is {to['elo_mae']}\")\n",
    "            \n",
    "            test_data_no_ties = test_data[test_data['Spread'] != 0]\n",
    "            to['our_brier'] = calc_our_brier(test_data_no_ties, variables, fit)\n",
    "            to['vegas_brier'] = calc_vegas_brier(test_data_no_ties)\n",
    "            to['elo_brier'] = calc_elo_brier()\n",
    "            \n",
    "            print(f\"Our Brier Score is {to['our_brier']}\")\n",
    "            print(f\"Vegas Brier Score is {to['vegas_brier']}\")\n",
    "            print(f\"ELO Brier Score is {to['elo_brier']}\")\n",
    "            \n",
    "            to['our_r2'] = calc_our_r2(test_data, variables, fit)\n",
    "        \n",
    "            print(f\"Our R-squared is {to['our_r2']}\")\n",
    "            \n",
    "            all_test_results[metric][Xtype].append(results)\n",
    "            if method == 'linear':\n",
    "                t = zip(fit.feature_names_in_, fit.coef_)\n",
    "                print(list(t))\n",
    "                print(fit.intercept_)\n",
    "        \n",
    "with open(\"test_results_nfl.json\", \"w\") as fp:\n",
    "    json.dump(all_test_results, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160846f6-5d30-405c-b10a-8e9ce5cf0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "resid = save_test_Y - save_test_pred_Y\n",
    "plt.plot(save_test_X['VNRPA'], resid, 'o')\n",
    "plt.xlabel(\"VNRPA\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual plot of best fit: Linear Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a1faa-b7df-4fa8-965d-741343020f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [(\"intercept\", save_fit.intercept_)]\n",
    "features_list.extend(list(zip(save_fit.feature_names_in_, save_fit.coef_)))\n",
    "team_list = features_list[5:]\n",
    "team_sorted_list = sorted(team_list, key=lambda x: x[1])\n",
    "features_list = features_list[:4]\n",
    "features_list.extend(team_sorted_list)\n",
    "df = pd.DataFrame(features_list, columns=['Feature', 'Coefficient'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec26aae-168b-440a-828b-fd37a21373eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(save_test_X['VNRPA'], save_test_Y, 'o')\n",
    "\n",
    "#obtain m (slope) and b(intercept) of linear regression line\n",
    "m2, m1, b = np.polyfit(save_test_X['VNRPA'], save_test_Y, 2)\n",
    "\n",
    "#add linear regression line to scatterplot \n",
    "plt.plot(save_test_X['VNRPA'], m2*(save_test_X['VNRPA']**2) + m1*save_test_X['VNRPA'] +b)\n",
    "plt.xlabel('VNRPA')\n",
    "plt.ylabel(\"True point spread\")\n",
    "plt.title(\"Plot of VNRPA vs. true point spread, with fitted polynomial\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89a30b-f6db-4747-b9b6-a9bb7054144d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
